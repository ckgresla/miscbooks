{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain Intro\n",
    "\n",
    "CKG getting up to speed on the main package being used\n",
    "\n",
    "* basically the `chains` (like LLMChain) let a model run its logic on specific sequence, and we can plug and play different chains into a sequential chain --> combine the input-outputs of each individual chain into a larger piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] #verify var correct in env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amole\n",
      "\n",
      "Holy guacamole is an exclamation of surprise or excitement. It is a play on the phrase \"holy cow\" and is often used in a humorous way.\n"
     ]
    }
   ],
   "source": [
    "# Calling a LLM w LangChain \n",
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0.2)\n",
    "\n",
    "prompt = \"holy guac\"\n",
    "out = llm(prompt)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are 100 good names for a company that makes wizard wands?\n"
     ]
    }
   ],
   "source": [
    "# Crafting a Template\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What are 100 good names for a company that makes {product}?\",\n",
    ")\n",
    "\n",
    "print(prompt.format(product=\"wizard wands\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['product'] template='What is a good name for a company that makes {product}?' template_format='f-string'\n"
     ]
    }
   ],
   "source": [
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining a Prompt/User Input to send to Model --> these are called \"chains\"\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt) #basically same ish as done @ brain, format prompt w a single var\n",
    "out = chain.run(\"wizard wands\") #subs in the var to the prompt we defined and then does forward pass w the model, wrapped in \".run\" method\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m the Weather Wizard\n",
      "\n",
      "\"Wizzy's Got the Power to Make it Rain or Shine!\"\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "\"Rain or Shine!\" -- The Weather Wizard's Motto\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished SimpleSequentialChain chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Rain or Shine!\" -- The Weather Wizard\\'s Motto'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One can wrap chains together in a \"SequentialChain\" --> \n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "p1 = PromptTemplate(\n",
    "    input_variables=[\"wizard_name\"],\n",
    "    template=\"Given a Wizard's Name and their Type, come up with an innovative and catchy phrase that describes them.\\n{wizard_name}\"\n",
    ")\n",
    "c1 = LLMChain(llm=llm, prompt=p1)\n",
    "\n",
    "p2 = PromptTemplate(\n",
    "    input_variables=[\"wizard\"],\n",
    "    template=\"Our wizard's catchphrase is {wizard} -- what might a suitable name and type be for this wizard's catchphrase?\"\n",
    ")\n",
    "c2 = LLMChain(llm=llm, prompt=p2)\n",
    "\n",
    "# Stitch the two sequences together\n",
    "main_chain = SimpleSequentialChain(chains=[c1, c2], verbose=True)\n",
    "main_chain.run(\"wizzy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "186cc7cc86c459e9f8500657a185d69bbd66532447edb6479cb82bc332e26019"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
