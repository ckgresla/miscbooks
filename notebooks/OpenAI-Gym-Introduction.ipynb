{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions & Answers below refer to HW 4 of IDS 576-Deep Learning -- it was here where I was exposed to the Gym package for the first time**\n",
    "\n",
    "**Q3.1** - The Cartpole Environment handles the RL variables in the following ways:\n",
    "- State: [cart position, cart velocity, pole angle, pole angular velocity] -> these 4 variables (contained in a Gym Box data structure) represent the cart & pole in the 2D RL environment\n",
    "- Actions: [0, 1] -> push cart left or right, respectively\n",
    "- Transitions: \n",
    "- Rewards: \n",
    "\n",
    "[OpenAI Gym Environments - Explained](https://blog.paperspace.com/getting-started-with-openai-gym/)\n",
    "\n",
    "[OpenAI Custom Environments](https://blog.paperspace.com/creating-custom-environments-openai-gym/)\n",
    "\n",
    "<BR>\n",
    "\n",
    "**Q3.2** - [dqn.py](https://github.com/seungeunrho/minimalRL/blob/master/dqn.py) is a Q-Network with the following architecture\n",
    "\n",
    "3 FC Layers\n",
    "1. Fully Connected [4 x 128] - environment at each step (or state) provides a input vector of __ to our model\n",
    "1. Fully Connected [128 x 128]\n",
    "1. Fully Connected [128 x 2] – 2 possible actions to take (in the \"CartPole-v1\" env)\n",
    "* All of which use 'relu' as a method of introducing nonlinearity (except the output layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/25/h27pt_w92kg0719dy47wtrx80000gn/T/ipykernel_49462/420770975.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Sample Code – Initialize Cartpole Env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CartPole-v1'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#env is convention used for environment variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# Sample Code – Initialize Cartpole Env\n",
    "import gym \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "env = gym.make('CartPole-v1') #env is convention used for environment variable\n",
    "#env = gym.make('MountainCar-v0') #env is convention used for environment variable\n",
    "\n",
    "\n",
    "# Observation and action space \n",
    "obs_space = env.observation_space\n",
    "action_space = env.action_space\n",
    "print(\"The observation space: {}\".format(obs_space)) #\n",
    "print(\"The action space: {}\".format(action_space)) #two discrete potential outputs for model\n",
    "#print(f\"Action Meanings: {env.action_space.contains([i for i in range(0, env.action_space.n)])}\")\n",
    "\n",
    "\n",
    "# env is created, now we can use it: \n",
    "for episode in range(10): \n",
    "    obs = env.reset()\n",
    "    for step in range(50):\n",
    "        action = env.action_space.sample()  # or given a custom model, action = policy(observation)\n",
    "        nobs, reward, done, info = env.step(action) #after determining action in above, pass to the step to 'take' the action\n",
    "        #new_observation, reward, done, info – what the env.step(action func returns)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/25/h27pt_w92kg0719dy47wtrx80000gn/T/ipykernel_49462/2534583884.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# reset the environment and see the initial observation - initial observation is random unless we set seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#can specify aa seed to make deterministic!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# reset the environment and see the initial observation - initial observation is random unless we set seed\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "env.seed(7) #can specify aa seed to make deterministic!\n",
    "\n",
    "# reset the environment and see the initial observation\n",
    "obs = env.reset()\n",
    "print(\"The initial observation is {}\".format(obs))\n",
    "\n",
    "# Sample a random action from the entire action space\n",
    "random_action = env.action_space.sample()\n",
    "\n",
    "# # Take the action and get the new observation space\n",
    "new_obs, reward, done, info = env.step(random_action)\n",
    "print(\"The new observation is {}\".format(new_obs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/25/h27pt_w92kg0719dy47wtrx80000gn/T/ipykernel_49462/3324370418.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# View the process – pop-up window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"human\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "# View the process – pop-up window\n",
    "env.render(mode = \"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff78c098750>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View Process - matplotlib image\n",
    "env_screen = env.render(mode = 'rgb_array')\n",
    "env.close()\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "plt.imshow(env_screen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typical RL Framework in Gym\n",
    "import time \n",
    "\n",
    "# Number of steps you run the agent for \n",
    "num_steps = 1000\n",
    "\n",
    "obs = env.reset() #initial env observation\n",
    "\n",
    "for step in range(num_steps):\n",
    "    # take random action, but you can also do something more intelligent\n",
    "    # action = my_intelligent_agent_fn(obs) \n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    # apply the action\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    \n",
    "    # Render the env\n",
    "    env.render()\n",
    "\n",
    "\n",
    "    # Wait a bit before the next frame unless you want to see a crazy fast video\n",
    "    time.sleep(0.001)\n",
    "    \n",
    "    # If the epsiode is up, then start another one (done == True)\n",
    "    if done:\n",
    "        env.reset()\n",
    "\n",
    "# Close the env -- at end of training/num steps\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gym.spaces.box.Box"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Classes from Gym\n",
    "type(env.action_space)\n",
    "type(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper Bound for Env Observation [0.6  0.07]\n",
      "Lower Bound for Env Observation [-1.2  -0.07]\n"
     ]
    }
   ],
   "source": [
    "# Limits of 2D Space for MountainCar env\n",
    "print(\"Upper Bound for Env Observation\", env.observation_space.high)\n",
    "print(\"Lower Bound for Env Observation\", env.observation_space.low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ML-Agents-Env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "3e30affdbb71e1e1a8b613bbaee9555d4e617202131987db9888c70b2d6aa14e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
